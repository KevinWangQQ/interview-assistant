// ğŸ¤– GPT-4é¢è¯•æ€»ç»“ç”ŸæˆæœåŠ¡ - åŸºäºè‹±æ–‡åŸæ–‡çš„é«˜è´¨é‡é¢è¯•åˆ†æ

import { InterviewTextChunker, TextChunk } from './text-chunking';
import { TranscriptionSegment } from '@/utils/smart-segmentation';

interface InterviewSummaryConfig {
  model: string;
  temperature: number;
  maxTokensPerRequest: number;
  summaryLanguage: 'zh' | 'en';
  analysisDepth: 'basic' | 'detailed' | 'comprehensive';
}

interface InterviewMetadata {
  duration: number; // åˆ†é’Ÿ
  participantCount: number;
  totalWords: number;
  questionCount: number;
  interactionCount: number;
}

interface InterviewSummary {
  id: string;
  timestamp: Date;
  metadata: InterviewMetadata;
  
  // æ ¸å¿ƒæ€»ç»“å†…å®¹
  executiveSummary: string;
  candidatePerformance: {
    overall: string;
    strengths: string[];
    weaknesses: string[];
    communicationSkills: string;
    technicalSkills: string;
  };
  keyInsights: {
    standoutMoments: string[];
    concerningAreas: string[];
    improvementSuggestions: string[];
  };
  recommendation: {
    decision: 'strongly_recommend' | 'recommend' | 'neutral' | 'not_recommend' | 'strongly_not_recommend';
    reasoning: string;
    nextSteps: string[];
  };
  
  // è¯¦ç»†åˆ†æ
  detailedAnalysis?: {
    questionResponseAnalysis: Array<{
      question: string;
      response: string;
      analysis: string;
      score: number; // 1-10
    }>;
    skillsAssessment: {
      [skillArea: string]: {
        score: number;
        evidence: string[];
        improvement: string;
      };
    };
  };
  
  // åŸå§‹æ•°æ®å¼•ç”¨
  sourceSegments: string[]; // åˆ†æ®µIDåˆ—è¡¨
  processingStats: {
    totalChunks: number;
    processingTime: number;
    confidenceScore: number;
  };
}

export class GPT4InterviewSummaryService {
  private config: InterviewSummaryConfig;
  private textChunker: InterviewTextChunker;

  constructor(config: Partial<InterviewSummaryConfig> = {}) {
    this.config = {
      model: 'gpt-4o', // ä½¿ç”¨æœ€æ–°çš„GPT-4oæ¨¡å‹
      temperature: 0.3, // è¾ƒä½æ¸©åº¦ç¡®ä¿ä¸€è‡´æ€§
      maxTokensPerRequest: 4000,
      summaryLanguage: 'zh',
      analysisDepth: 'detailed',
      ...config
    };

    this.textChunker = new InterviewTextChunker({
      maxTokensPerChunk: 3000,
      overlapTokens: 300,
      preserveContext: true
    });
  }

  // ğŸ¯ ç”Ÿæˆé¢è¯•æ€»ç»“çš„ä¸»è¦æ–¹æ³•
  async generateInterviewSummary(
    segments: TranscriptionSegment[],
    metadata?: Partial<InterviewMetadata>
  ): Promise<InterviewSummary> {
    console.log('ğŸ¤– å¼€å§‹ç”ŸæˆGPT-4é¢è¯•æ€»ç»“');
    
    const startTime = Date.now();
    
    try {
      // 1. å‡†å¤‡å’Œåˆ†æåŸå§‹æ•°æ®
      const interviewData = this.prepareInterviewData(segments, metadata);
      
      // 2. åˆ†å—å¤„ç†é•¿æ–‡æœ¬
      const chunks = this.textChunker.chunkText(
        interviewData.fullTranscript,
        interviewData.timeSegments
      );
      
      console.log('ğŸ“š æ–‡æœ¬åˆ†å—å®Œæˆ:', {
        chunks: chunks.length,
        totalTokens: chunks.reduce((sum, c) => sum + c.tokenCount, 0)
      });
      
      // 3. ç”Ÿæˆåˆ†å—åˆ†æ
      const chunkAnalyses = await this.analyzeChunks(chunks, interviewData.metadata);
      
      // 4. ç»¼åˆç”Ÿæˆæœ€ç»ˆæ€»ç»“
      const finalSummary = await this.generateComprehensiveSummary(
        chunkAnalyses,
        interviewData,
        chunks
      );
      
      const processingTime = Date.now() - startTime;
      
      // 5. æ„å»ºå®Œæ•´æ€»ç»“å¯¹è±¡
      const summary: InterviewSummary = {
        id: `summary-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`,
        timestamp: new Date(),
        metadata: interviewData.metadata,
        ...finalSummary,
        sourceSegments: segments.map(s => s.id),
        processingStats: {
          totalChunks: chunks.length,
          processingTime,
          confidenceScore: this.calculateConfidenceScore(chunkAnalyses)
        }
      };
      
      console.log('âœ… GPT-4é¢è¯•æ€»ç»“ç”Ÿæˆå®Œæˆ:', {
        id: summary.id,
        processingTime: `${processingTime}ms`,
        recommendationDecision: summary.recommendation.decision,
        confidenceScore: summary.processingStats.confidenceScore
      });
      
      return summary;
      
    } catch (error) {
      console.error('âŒ GPT-4é¢è¯•æ€»ç»“ç”Ÿæˆå¤±è´¥:', error);
      throw new Error(`é¢è¯•æ€»ç»“ç”Ÿæˆå¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  }

  // ğŸ“Š å‡†å¤‡é¢è¯•æ•°æ®
  private prepareInterviewData(
    segments: TranscriptionSegment[],
    metadata?: Partial<InterviewMetadata>
  ) {
    // æŒ‰æ—¶é—´æ’åºåˆ†æ®µ
    const sortedSegments = [...segments].sort((a, b) => a.startTime - b.startTime);
    
    // æ„å»ºå®Œæ•´è½¬å½•æ–‡æœ¬ï¼ˆä½¿ç”¨è‹±æ–‡åŸæ–‡ï¼‰
    const fullTranscript = sortedSegments
      .map(segment => {
        const timestamp = `[${Math.floor(segment.startTime / 60)}:${(segment.startTime % 60).toFixed(0).padStart(2, '0')}]`;
        const speaker = segment.speaker === 'interviewer' ? 'Interviewer' : 'Candidate';
        return `${timestamp} ${speaker}: ${segment.englishText}`;
      })
      .join('\n\n');
    
    // è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    const duration = sortedSegments.length > 0 ? 
      Math.max(...sortedSegments.map(s => s.endTime)) / 60 : 0;
    
    const totalWords = sortedSegments.reduce((sum, s) => sum + s.wordCount, 0);
    const questionCount = sortedSegments.reduce((sum, s) => 
      sum + (s.englishText.match(/\?/g) || []).length, 0
    );
    
    const interviewMetadata: InterviewMetadata = {
      duration: Math.round(duration),
      participantCount: 2, // é»˜è®¤é¢è¯•å®˜å’Œå€™é€‰äºº
      totalWords,
      questionCount,
      interactionCount: sortedSegments.length,
      ...metadata
    };
    
    // å‡†å¤‡æ—¶é—´åˆ†æ®µä¿¡æ¯
    const timeSegments = sortedSegments.map(segment => ({
      start: segment.startTime,
      end: segment.endTime,
      text: segment.englishText
    }));
    
    return {
      fullTranscript,
      timeSegments,
      metadata: interviewMetadata,
      segments: sortedSegments
    };
  }

  // ğŸ” åˆ†ææ–‡æœ¬å—
  private async analyzeChunks(
    chunks: TextChunk[],
    metadata: InterviewMetadata
  ): Promise<Array<{
    chunkId: string;
    analysis: any;
    keyPoints: string[];
    concerns: string[];
    questions: Array<{ question: string; response: string; quality: number }>;
  }>> {
    console.log('ğŸ” å¼€å§‹åˆ†å—åˆ†æ...');
    
    const analyses = [];
    
    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      console.log(`ğŸ“„ åˆ†æå— ${i + 1}/${chunks.length}...`);
      
      try {
        const prompt = this.buildChunkAnalysisPrompt(chunk, metadata, i, chunks.length);
        const analysis = await this.callGPT4(prompt);
        
        // è§£æGPT-4å“åº”
        const parsedAnalysis = this.parseChunkAnalysis(analysis);
        
        analyses.push({
          chunkId: chunk.id,
          analysis: parsedAnalysis,
          keyPoints: parsedAnalysis.keyPoints || [],
          concerns: parsedAnalysis.concerns || [],
          questions: parsedAnalysis.questions || []
        });
        
        // æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
        await this.delay(200);
        
      } catch (error) {
        console.error(`âŒ åˆ†æå— ${chunk.id} å¤±è´¥:`, error);
        // æ·»åŠ é”™è¯¯å ä½ç¬¦
        analyses.push({
          chunkId: chunk.id,
          analysis: { error: 'åˆ†æå¤±è´¥' },
          keyPoints: [],
          concerns: ['æ­¤éƒ¨åˆ†åˆ†æå¤±è´¥'],
          questions: []
        });
      }
    }
    
    console.log('âœ… åˆ†å—åˆ†æå®Œæˆ');
    return analyses;
  }

  // ğŸ—ï¸ æ„å»ºåˆ†å—åˆ†ææç¤ºè¯
  private buildChunkAnalysisPrompt(
    chunk: TextChunk,
    metadata: InterviewMetadata,
    chunkIndex: number,
    totalChunks: number
  ): string {
    return `ä½ æ˜¯ä¸“ä¸šçš„é¢è¯•åˆ†æä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹é¢è¯•è½¬å½•ç‰‡æ®µï¼Œè¿™æ˜¯ç¬¬${chunkIndex + 1}/${totalChunks}ä¸ªç‰‡æ®µã€‚

é¢è¯•åŸºæœ¬ä¿¡æ¯ï¼š
- æ€»æ—¶é•¿ï¼š${metadata.duration}åˆ†é’Ÿ
- æ€»è¯æ•°ï¼š${metadata.totalWords}
- é—®é¢˜æ•°é‡ï¼š${metadata.questionCount}

è½¬å½•ç‰‡æ®µå†…å®¹ï¼š
${chunk.content}

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼åˆ†ææ­¤ç‰‡æ®µï¼š

{
  "keyPoints": ["å…³é”®è¡¨ç°ç‚¹1", "å…³é”®è¡¨ç°ç‚¹2"],
  "concerns": ["å…³æ³¨ç‚¹1", "å…³æ³¨ç‚¹2"],
  "questions": [
    {
      "question": "é—®é¢˜å†…å®¹",
      "response": "å›ç­”å†…å®¹", 
      "quality": 8,
      "analysis": "å›ç­”è´¨é‡åˆ†æ"
    }
  ],
  "skills": {
    "communication": { "score": 8, "evidence": ["è¯æ®1"] },
    "technical": { "score": 7, "evidence": ["è¯æ®1"] },
    "problemSolving": { "score": 6, "evidence": ["è¯æ®1"] }
  },
  "overall": "æ­¤ç‰‡æ®µçš„æ•´ä½“è¯„ä»·"
}

è¦æ±‚ï¼š
1. ä¸“æ³¨äºå€™é€‰äººçš„è¡¨ç°åˆ†æ
2. åŸºäºå…·ä½“è¯æ®ç»™å‡ºè¯„åˆ†
3. è¯†åˆ«çªå‡ºçš„ä¼˜ç¼ºç‚¹
4. ä¿æŒå®¢è§‚ä¸“ä¸šçš„åˆ†æè§’åº¦
5. ä½¿ç”¨ä¸­æ–‡è¾“å‡º`;
  }

  // ğŸ”„ ç»¼åˆç”Ÿæˆæœ€ç»ˆæ€»ç»“
  private async generateComprehensiveSummary(
    chunkAnalyses: any[],
    interviewData: any,
    chunks: TextChunk[]
  ) {
    console.log('ğŸ”„ ç”Ÿæˆç»¼åˆæ€»ç»“...');
    
    // æ•´åˆæ‰€æœ‰åˆ†å—åˆ†æ
    const consolidatedAnalysis = this.consolidateChunkAnalyses(chunkAnalyses);
    
    // æ„å»ºç»¼åˆåˆ†ææç¤ºè¯
    const prompt = this.buildComprehensiveSummaryPrompt(
      consolidatedAnalysis,
      interviewData.metadata,
      chunks
    );
    
    try {
      const summaryResponse = await this.callGPT4(prompt, 'comprehensive');
      return this.parseComprehensiveSummary(summaryResponse);
    } catch (error) {
      console.error('âŒ ç»¼åˆæ€»ç»“ç”Ÿæˆå¤±è´¥:', error);
      throw error;
    }
  }

  // ğŸ—ï¸ æ„å»ºç»¼åˆæ€»ç»“æç¤ºè¯
  private buildComprehensiveSummaryPrompt(
    consolidatedAnalysis: any,
    metadata: InterviewMetadata,
    chunks: TextChunk[]
  ): string {
    return `ä½ æ˜¯èµ„æ·±çš„HRé¢è¯•ä¸“å®¶ã€‚åŸºäºä»¥ä¸‹é¢è¯•åˆ†ææ•°æ®ï¼Œç”Ÿæˆå®Œæ•´çš„é¢è¯•è¯„ä¼°æŠ¥å‘Šã€‚

é¢è¯•åŸºæœ¬ä¿¡æ¯ï¼š
- æ—¶é•¿ï¼š${metadata.duration}åˆ†é’Ÿ
- æ€»è¯æ•°ï¼š${metadata.totalWords}
- äº’åŠ¨æ¬¡æ•°ï¼š${metadata.interactionCount}
- é—®é¢˜æ•°é‡ï¼š${metadata.questionCount}

åˆ†å—åˆ†ææ±‡æ€»ï¼š
${JSON.stringify(consolidatedAnalysis, null, 2)}

è¯·ç”Ÿæˆå®Œæ•´çš„é¢è¯•è¯„ä¼°æŠ¥å‘Šï¼Œä½¿ç”¨ä»¥ä¸‹JSONæ ¼å¼ï¼š

{
  "executiveSummary": "200å­—å†…çš„æ‰§è¡Œæ‘˜è¦ï¼Œæ¦‚è¿°å€™é€‰äººæ•´ä½“è¡¨ç°",
  "candidatePerformance": {
    "overall": "æ•´ä½“è¡¨ç°è¯„ä»·",
    "strengths": ["ä¼˜åŠ¿1", "ä¼˜åŠ¿2", "ä¼˜åŠ¿3"],
    "weaknesses": ["ä¸è¶³1", "ä¸è¶³2"],
    "communicationSkills": "æ²Ÿé€šèƒ½åŠ›å…·ä½“è¯„ä»·",
    "technicalSkills": "æŠ€æœ¯èƒ½åŠ›å…·ä½“è¯„ä»·"
  },
  "keyInsights": {
    "standoutMoments": ["äº®ç‚¹æ—¶åˆ»1", "äº®ç‚¹æ—¶åˆ»2"],
    "concerningAreas": ["å…³æ³¨é¢†åŸŸ1", "å…³æ³¨é¢†åŸŸ2"],
    "improvementSuggestions": ["æ”¹è¿›å»ºè®®1", "æ”¹è¿›å»ºè®®2", "æ”¹è¿›å»ºè®®3"]
  },
  "recommendation": {
    "decision": "recommend",
    "reasoning": "æ¨èç†ç”±çš„è¯¦ç»†è¯´æ˜",
    "nextSteps": ["åç»­æ­¥éª¤1", "åç»­æ­¥éª¤2"]
  },
  "detailedAnalysis": {
    "skillsAssessment": {
      "communication": {
        "score": 8,
        "evidence": ["è¯æ®1", "è¯æ®2"],
        "improvement": "æ”¹è¿›å»ºè®®"
      },
      "technical": {
        "score": 7,
        "evidence": ["è¯æ®1", "è¯æ®2"],
        "improvement": "æ”¹è¿›å»ºè®®"
      },
      "problemSolving": {
        "score": 6,
        "evidence": ["è¯æ®1", "è¯æ®2"],
        "improvement": "æ”¹è¿›å»ºè®®"
      },
      "leadership": {
        "score": 5,
        "evidence": ["è¯æ®1", "è¯æ®2"],
        "improvement": "æ”¹è¿›å»ºè®®"
      }
    }
  }
}

è¯„ä¼°æ ‡å‡†ï¼š
- decisioné€‰é¡¹ï¼šstrongly_recommend, recommend, neutral, not_recommend, strongly_not_recommend
- scoreèŒƒå›´ï¼š1-10åˆ†
- åŸºäºå…·ä½“äº‹å®å’Œè¯æ®è¿›è¡Œè¯„ä»·
- ä¿æŒå®¢è§‚ä¸“ä¸šçš„è¯„ä¼°æ€åº¦
- æä¾›å…·ä½“å¯è¡Œçš„æ”¹è¿›å»ºè®®`;
  }

  // ğŸ”§ è°ƒç”¨GPT-4 API
  private async callGPT4(prompt: string, type: 'chunk' | 'comprehensive' = 'chunk'): Promise<string> {
    const maxTokens = type === 'comprehensive' ? 2000 : 1000;
    
    try {
      // è·å–APIå¯†é’¥
      const apiKey = await this.getAPIKey();
      
      const response = await fetch('https://api.openai.com/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: this.config.model,
          messages: [
            {
              role: 'system',
              content: 'ä½ æ˜¯ä¸“ä¸šçš„é¢è¯•åˆ†æä¸“å®¶ï¼Œæ“…é•¿åˆ†æå€™é€‰äººè¡¨ç°å¹¶æä¾›å®¢è§‚å‡†ç¡®çš„è¯„ä¼°ã€‚è¯·å§‹ç»ˆä½¿ç”¨ä¸­æ–‡å›å¤ï¼Œå¹¶æä¾›ç»“æ„åŒ–çš„åˆ†æç»“æœã€‚'
            },
            {
              role: 'user',
              content: prompt
            }
          ],
          temperature: this.config.temperature,
          max_tokens: maxTokens,
          response_format: { type: 'json_object' }
        })
      });

      if (!response.ok) {
        throw new Error(`GPT-4 APIè°ƒç”¨å¤±è´¥: ${response.status} ${response.statusText}`);
      }

      const data = await response.json();
      
      if (!data.choices || data.choices.length === 0) {
        throw new Error('GPT-4 APIè¿”å›ç©ºç»“æœ');
      }

      return data.choices[0].message.content;
      
    } catch (error) {
      console.error('âŒ GPT-4 APIè°ƒç”¨å¤±è´¥:', error);
      throw error;
    }
  }

  // ğŸ”‘ è·å–APIå¯†é’¥ - ä½¿ç”¨ç»Ÿä¸€çš„APIå¯†é’¥ç®¡ç†å™¨
  private async getAPIKey(): Promise<string> {
    try {
      // åŠ¨æ€å¯¼å…¥APIå¯†é’¥ç®¡ç†å™¨ï¼ˆé¿å…å¾ªç¯å¯¼å…¥ï¼‰
      const { ApiKeyManager } = await import('@/lib/api-key-manager');
      const apiKeyManager = ApiKeyManager.getInstance();
      return apiKeyManager.getOpenAIApiKey();
    } catch (error) {
      console.error('âŒ è·å–APIå¯†é’¥å¤±è´¥:', error);
      throw new Error('æœªæ‰¾åˆ°OpenAI APIå¯†é’¥ï¼Œè¯·åœ¨è®¾ç½®é¡µé¢é…ç½®');
    }
  }

  // ğŸ“– è§£æåˆ†å—åˆ†æç»“æœ
  private parseChunkAnalysis(response: string): any {
    try {
      return JSON.parse(response);
    } catch (error) {
      console.error('âŒ è§£æåˆ†å—åˆ†æç»“æœå¤±è´¥:', error);
      return {
        keyPoints: [],
        concerns: ['è§£æå¤±è´¥'],
        questions: [],
        skills: {},
        overall: 'åˆ†æè§£æå¤±è´¥'
      };
    }
  }

  // ğŸ“– è§£æç»¼åˆæ€»ç»“ç»“æœ
  private parseComprehensiveSummary(response: string): any {
    try {
      return JSON.parse(response);
    } catch (error) {
      console.error('âŒ è§£æç»¼åˆæ€»ç»“å¤±è´¥:', error);
      throw new Error('æ€»ç»“ç»“æœè§£æå¤±è´¥');
    }
  }

  // ğŸ”„ æ•´åˆåˆ†å—åˆ†æ
  private consolidateChunkAnalyses(analyses: any[]): any {
    const allKeyPoints = analyses.flatMap(a => a.keyPoints || []);
    const allConcerns = analyses.flatMap(a => a.concerns || []);
    const allQuestions = analyses.flatMap(a => a.questions || []);
    
    // æŠ€èƒ½è¯„åˆ†å¹³å‡å€¼
    const skillScores: { [key: string]: number[] } = {};
    analyses.forEach(analysis => {
      if (analysis.analysis && analysis.analysis.skills) {
        Object.entries(analysis.analysis.skills).forEach(([skill, data]: [string, any]) => {
          if (!skillScores[skill]) skillScores[skill] = [];
          if (data.score) skillScores[skill].push(data.score);
        });
      }
    });
    
    const averageSkillScores = Object.entries(skillScores).reduce((acc, [skill, scores]) => {
      acc[skill] = scores.length > 0 ? Math.round(scores.reduce((sum, score) => sum + score, 0) / scores.length) : 0;
      return acc;
    }, {} as { [key: string]: number });
    
    return {
      keyPoints: [...new Set(allKeyPoints)], // å»é‡
      concerns: [...new Set(allConcerns)],
      questions: allQuestions,
      averageSkillScores,
      totalAnalyses: analyses.length
    };
  }

  // ğŸ¯ è®¡ç®—ä¿¡å¿ƒåº¦è¯„åˆ†
  private calculateConfidenceScore(analyses: any[]): number {
    const successfulAnalyses = analyses.filter(a => !a.analysis.error).length;
    const successRate = analyses.length > 0 ? successfulAnalyses / analyses.length : 0;
    
    // åŸºç¡€ä¿¡å¿ƒåº¦åŸºäºæˆåŠŸç‡
    let confidence = successRate * 0.7;
    
    // æ ¹æ®æ•°æ®é‡è°ƒæ•´
    if (analyses.length >= 5) confidence += 0.2;
    else if (analyses.length >= 3) confidence += 0.1;
    
    // æ ¹æ®åˆ†æè´¨é‡è°ƒæ•´
    const avgQuestions = analyses.reduce((sum, a) => sum + (a.questions?.length || 0), 0) / analyses.length;
    if (avgQuestions >= 2) confidence += 0.1;
    
    return Math.min(0.95, Math.max(0.1, confidence));
  }

  // â±ï¸ å»¶è¿Ÿå‡½æ•°
  private delay(ms: number): Promise<void> {
    return new Promise(resolve => setTimeout(resolve, ms));
  }

  // âš™ï¸ æ›´æ–°é…ç½®
  updateConfig(newConfig: Partial<InterviewSummaryConfig>): void {
    this.config = { ...this.config, ...newConfig };
    console.log('âš™ï¸ GPT-4æ€»ç»“æœåŠ¡é…ç½®å·²æ›´æ–°:', this.config);
  }

  // ğŸ”§ è·å–å½“å‰é…ç½®
  getConfig(): InterviewSummaryConfig {
    return { ...this.config };
  }
}

export type { InterviewSummary, InterviewSummaryConfig, InterviewMetadata };