// ğŸµ WAVæµå¼Store - ä½¿ç”¨WAVæ ¼å¼ç¡®ä¿Whisperå…¼å®¹

import { create } from 'zustand';
import { devtools } from 'zustand/middleware';
import { EnhancedWAVStreamingTranscriptionService } from '@/services/streaming/enhanced-wav-streaming-transcription';

interface WAVStreamingState {
  isActive: boolean;
  isProcessing: boolean;
  currentText: string;
  currentTranslation: string;
  segments: any[];
  streamingService: EnhancedWAVStreamingTranscriptionService | null;
  error: string | null;
  lastSavedTimestamp: number | null;
  interviewInfo: {
    candidateName: string;
    position: string;
  } | null;
  config: {
    chunkInterval: number;
    translationDelay: number;
  };
}

interface WAVStreamingActions {
  startStreaming: (interviewInfo?: { candidateName: string; position: string }) => Promise<void>;
  stopStreaming: () => Promise<void>;
  generateSummaryAndSave: () => Promise<any>;
  saveInterviewSession: () => Promise<void>;
  handleTranscriptionUpdate: (data: any) => void;
  handleTranslationUpdate: (data: any) => void;
  handleSegmentCreated: (data: any) => void;
  handleError: (data: any) => void;
  setError: (error: string | null) => void;
  clearError: () => void;
  reset: () => void;
}

type WAVStreamingStore = WAVStreamingState & WAVStreamingActions;

const initialState: WAVStreamingState = {
  isActive: false,
  isProcessing: false,
  currentText: '',
  currentTranslation: '',
  segments: [],
  streamingService: null,
  error: null,
  lastSavedTimestamp: null,
  interviewInfo: null,
  config: {
    chunkInterval: 3000,
    translationDelay: 1000
  }
};

export const useWAVStreamingStore = create<WAVStreamingStore>()(
  devtools(
    (set, get) => ({
      ...initialState,

      startStreaming: async (interviewInfo?: { candidateName: string; position: string }) => {
        try {
          console.log('ğŸµ å¯åŠ¨WAVæµå¼å¤„ç†', interviewInfo);
          
          const { config } = get();
          
          // ä¿å­˜é¢è¯•ä¿¡æ¯
          set({ interviewInfo });
          
          const streamingService = new EnhancedWAVStreamingTranscriptionService({
            chunkInterval: config.chunkInterval,
            translationDelay: config.translationDelay,
            enableSystemAudio: true,
            audioQualityThreshold: 0.1
          });

          streamingService.addEventListener('transcription_update', (event) => {
            get().handleTranscriptionUpdate(event.data);
          });

          streamingService.addEventListener('translation_update', (event) => {
            get().handleTranslationUpdate(event.data);
          });

          streamingService.addEventListener('segment_created', (event) => {
            get().handleSegmentCreated(event.data);
          });

          streamingService.addEventListener('error', (event) => {
            get().handleError(event.data);
          });

          await streamingService.startStreaming();
          
          set({ 
            streamingService,
            isActive: true,
            isProcessing: true,
            error: null
          });
          
          console.log('âœ… WAVæµå¼å¤„ç†å¯åŠ¨æˆåŠŸ');
        } catch (error) {
          const errorMessage = error instanceof Error ? error.message : 'å¯åŠ¨å¤±è´¥';
          console.error('âŒ å¯åŠ¨WAVæµå¼å¤„ç†å¤±è´¥:', error);
          get().setError(`å¯åŠ¨å¤±è´¥: ${errorMessage}`);
        }
      },

      stopStreaming: async () => {
        try {
          const { streamingService, segments } = get();
          
          if (streamingService) {
            await streamingService.stopStreaming();
          }
          
          // ğŸ—ï¸ è‡ªåŠ¨ä¿å­˜é¢è¯•ä¼šè¯ï¼ˆå³ä½¿æ²¡æœ‰è½¬å½•å†…å®¹ä¹Ÿä¿å­˜åŸºç¡€è®°å½•ï¼‰
          console.log('ğŸ” åœæ­¢å½•åˆ¶æ£€æŸ¥ - segmentsæ•°é‡:', segments.length);
          try {
            console.log('ğŸ’¾ å¼€å§‹è‡ªåŠ¨ä¿å­˜é¢è¯•ä¼šè¯...');
            await get().saveInterviewSession();
            console.log('âœ… é¢è¯•ä¼šè¯å·²è‡ªåŠ¨ä¿å­˜åˆ°å†å²è®°å½•');
          } catch (error) {
            console.error('âŒ è‡ªåŠ¨ä¿å­˜é¢è¯•ä¼šè¯å¤±è´¥:', error);
          }
          
          set({ 
            streamingService: null,
            isActive: false,
            isProcessing: false,
            currentText: '',
            currentTranslation: '',
            error: null
            // æ³¨æ„ï¼šä¸æ¸…ç©º segmentsï¼Œä¿ç•™è½¬å½•æ•°æ®ä¾›åç»­ä½¿ç”¨
          });
          
          console.log('âœ… WAVæµå¼å¤„ç†å·²åœæ­¢');
        } catch (error) {
          console.error('âŒ åœæ­¢WAVæµå¼å¤„ç†å¤±è´¥:', error);
        }
      },

      handleTranscriptionUpdate: (data: any) => {
        console.log('ğŸ“ WAVè½¬å½•æ›´æ–°:', data.text);
        set({
          currentText: data.text,
          isProcessing: true
        });
      },

      handleTranslationUpdate: (data: any) => {
        console.log('ğŸŒ WAVç¿»è¯‘æ›´æ–°:', data.translation);
        set({
          currentText: data.text,
          currentTranslation: data.translation,
          isProcessing: false
        });
      },

      handleSegmentCreated: (data: any) => {
        console.log('ğŸ“¦ æ–°åˆ†æ®µåˆ›å»º:', data.segment.id);
        const { segments } = get();
        set({
          segments: [...segments, data.segment],
          // åˆ†æ®µåˆ›å»ºåï¼Œæ¸…ç©ºå½“å‰æ˜¾ç¤ºçš„æ–‡æœ¬ï¼Œå‡†å¤‡ä¸‹ä¸€åˆ†æ®µ
          currentText: '',
          currentTranslation: '',
          isProcessing: false
        });
      },

      handleError: (data: any) => {
        console.error('âŒ WAVæµå¼å¤„ç†é”™è¯¯:', data);
        const errorMessage = data.message || 'æœªçŸ¥é”™è¯¯';
        get().setError(errorMessage);
        set({ isProcessing: false });
      },

      setError: (error) => set({ error }),
      clearError: () => set({ error: null }),

      saveInterviewSession: async () => {
        try {
          const { segments, lastSavedTimestamp } = get();
          console.log('ğŸ’¾ saveInterviewSession è¢«è°ƒç”¨ï¼Œsegmentsæ•°é‡:', segments.length);
          
          // é˜²æ­¢çŸ­æ—¶é—´å†…é‡å¤ä¿å­˜ï¼ˆ5ç§’å†…ä¸é‡å¤ä¿å­˜ï¼‰
          const now = Date.now();
          if (lastSavedTimestamp && (now - lastSavedTimestamp) < 5000) {
            console.log('âš ï¸ è·ç¦»ä¸Šæ¬¡ä¿å­˜æ—¶é—´è¿‡çŸ­ï¼Œè·³è¿‡é‡å¤ä¿å­˜');
            return;
          }

          console.log('ğŸ’¾ ä¿å­˜åŸºç¡€é¢è¯•ä¼šè¯...');
          
          // å¯¼å…¥å­˜å‚¨æœåŠ¡
          const { EnhancedInterviewStorageService } = await import('@/services/storage/enhanced-interview-storage');
          const storageService = new EnhancedInterviewStorageService();
          
          // ä½¿ç”¨ä¿å­˜çš„é¢è¯•ä¿¡æ¯
          const { interviewInfo } = get();
          const candidateName = interviewInfo?.candidateName || 'unknown';
          const position = interviewInfo?.position || 'æœªæŒ‡å®šèŒä½';
          const company = '';
          
          // åˆ›å»ºåŸºç¡€é¢è¯•ä¼šè¯è®°å½•ï¼ˆä¸åŒ…å«æ€»ç»“ï¼‰
          const interviewSession = {
            id: `interview-${Date.now()}`,
            timestamp: new Date(),
            lastUpdated: new Date(),
            candidateName,
            position,
            interviewerName: 'é¢è¯•å®˜',
            company,
            category: 'technical' as const,
            difficulty: 'mid' as const,
            tags: [],
            recordingSession: {
              id: `recording-${Date.now()}`,
              startTime: new Date(Date.now() - segments.length * 30000), // ä¼°ç®—å¼€å§‹æ—¶é—´
              endTime: new Date(),
              duration: segments.length * 30, // ä¼°ç®—æ—¶é•¿ï¼ˆç§’ï¼‰
              status: 'completed' as const,
              audioConfig: {
                microphoneEnabled: true,
                systemAudioEnabled: false,
                sampleRate: 16000,
                channels: 1,
                format: 'wav'
              },
              audioQualityHistory: [],
              averageAudioQuality: 0.8
            },
            segments: segments.length > 0 ? segments.map((seg: any) => ({
              ...seg,
              timestamp: new Date(seg.timestamp || Date.now()),
              startTime: seg.startTime || 0,
              endTime: seg.endTime || 30,
              englishText: seg.text || seg.englishText || '',
              chineseText: seg.translation || seg.chineseText || '',
              speaker: seg.speaker || 'unknown',
              confidence: seg.confidence || 0.8
            })) : [{
              id: `empty-segment-${Date.now()}`,
              timestamp: new Date(),
              startTime: 0,
              endTime: 30,
              englishText: '(æ— è½¬å½•å†…å®¹)',
              chineseText: '(æ— è½¬å½•å†…å®¹)',
              speaker: 'unknown',
              confidence: 0
            }],
            rawTranscriptionText: segments.map((seg: any) => seg.text || seg.englishText || '').join(' '),
            rawTranslationText: segments.map((seg: any) => seg.translation || seg.chineseText || '').join(' '),
            statistics: {
              totalWords: segments.reduce((count: number, seg: any) => 
                count + (seg.text || seg.englishText || '').split(' ').length, 0),
              totalQuestions: segments.filter((seg: any) => 
                (seg.text || seg.englishText || '').includes('?')).length,
              speakerChangeCount: new Set(segments.map((seg: any) => seg.speaker)).size,
              averageSegmentDuration: segments.length > 0 ? 
                segments.reduce((sum: number, seg: any) => sum + (seg.endTime - seg.startTime || 30), 0) / segments.length : 0,
              longestSegmentDuration: segments.length > 0 ? 
                Math.max(...segments.map((seg: any) => seg.endTime - seg.startTime || 30)) : 0,
              speakingTimeDistribution: {
                interviewer: segments.filter((seg: any) => seg.speaker === 'interviewer')
                  .reduce((sum: number, seg: any) => sum + (seg.endTime - seg.startTime || 30), 0),
                candidate: segments.filter((seg: any) => seg.speaker === 'candidate')
                  .reduce((sum: number, seg: any) => sum + (seg.endTime - seg.startTime || 30), 0),
                unknown: segments.filter((seg: any) => !seg.speaker || seg.speaker === 'unknown')
                  .reduce((sum: number, seg: any) => sum + (seg.endTime - seg.startTime || 30), 0)
              },
              interactionMetrics: {
                responseTime: [],
                questionDepth: 3,
                engagementScore: 0.7
              }
            },
            metadata: {
              deviceInfo: navigator.userAgent || 'Unknown',
              browserInfo: navigator.userAgent || 'Unknown',
              networkQuality: 'good' as const,
              recordingQuality: 'high' as const,
              processingVersion: '1.0.0'
            },
            status: 'completed' as const,
            isBookmarked: false,
            confidentialityLevel: 'internal' as const
            // æ³¨æ„ï¼šæ²¡æœ‰ summary å’Œ summaryGenerationStatus
          };
          
          // ä¿å­˜åˆ°æœ¬åœ°å­˜å‚¨
          await storageService.saveSession(interviewSession);
          
          // æ›´æ–°æœ€åä¿å­˜æ—¶é—´æˆ³
          set({ lastSavedTimestamp: now });
          
          console.log('âœ… åŸºç¡€é¢è¯•ä¼šè¯ä¿å­˜æˆåŠŸ');
          
        } catch (error) {
          console.error('âŒ ä¿å­˜åŸºç¡€é¢è¯•ä¼šè¯å¤±è´¥:', error);
          throw error;
        }
      },

      generateSummaryAndSave: async () => {
        try {
          const { segments, interviewInfo } = get();
          if (segments.length === 0) return;

          console.log('ğŸ“Š å¼€å§‹ç”Ÿæˆé¢è¯•æ€»ç»“...');
          
          // å¯¼å…¥æ€»ç»“æœåŠ¡
          const { GPT4InterviewSummaryService } = await import('@/services/interview-summary/gpt4-summary-service');
          const { EnhancedInterviewStorageService } = await import('@/services/storage/enhanced-interview-storage');
          
          const summaryService = new GPT4InterviewSummaryService();
          const storageService = new EnhancedInterviewStorageService();
          
          // ç”Ÿæˆæ€»ç»“ï¼ˆä¼ å…¥é¢è¯•ä¿¡æ¯ï¼‰
          const summary = await summaryService.generateInterviewSummary(
            segments, 
            undefined, 
            interviewInfo || undefined
          );
          
          // åˆ›å»ºé¢è¯•ä¼šè¯è®°å½•
          const interviewSession = {
            id: `interview-${Date.now()}`,
            timestamp: new Date(),
            lastUpdated: new Date(),
            candidateName: interviewInfo?.candidateName || 'unknown',
            position: interviewInfo?.position || 'æœªæŒ‡å®šèŒä½',
            interviewerName: 'é¢è¯•å®˜',
            company: '',
            recordingSession: {
              id: `recording-${Date.now()}`,
              startTime: new Date(),
              endTime: new Date(),
              duration: 0,
              status: 'completed' as const,
              audioConfig: {
                microphoneEnabled: true,
                systemAudioEnabled: false,
                sampleRate: 16000,
                channels: 1,
                format: 'wav'
              },
              audioQualityHistory: [],
              averageAudioQuality: 0.8
            },
            segments: segments,
            rawTranscriptionText: segments.map((seg: any) => seg.text).join(' '),
            rawTranslationText: segments.map((seg: any) => seg.translation).join(' '),
            summary: summary,
            statistics: {
              totalWords: segments.reduce((sum: number, seg: any) => sum + (seg.wordCount || 0), 0),
              totalQuestions: 0,
              speakerChangeCount: 0,
              averageSegmentDuration: 0,
              longestSegmentDuration: 0,
              speakingTimeDistribution: {
                interviewer: 0,
                candidate: 0,
                unknown: 0
              },
              interactionMetrics: {
                responseTime: [],
                questionDepth: 0,
                engagementScore: 0
              }
            },
            tags: [],
            category: 'mixed' as const,
            difficulty: 'mid' as const,
            metadata: {
              recordingQuality: 'high' as const,
              processingVersion: '1.0.0'
            },
            status: 'completed' as const,
            isBookmarked: false,
            confidentialityLevel: 'internal' as const
          };
          
          // ä¿å­˜åˆ°æœ¬åœ°å­˜å‚¨
          await storageService.saveSession(interviewSession);
          
          console.log('âœ… é¢è¯•æ€»ç»“ç”Ÿæˆå¹¶ä¿å­˜æˆåŠŸ');
          
          return summary;
          
        } catch (error) {
          console.error('âŒ ç”Ÿæˆæ€»ç»“å¤±è´¥:', error);
          get().setError(`ç”Ÿæˆæ€»ç»“å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
          throw error;
        }
      },

      reset: () => {
        const { streamingService } = get();
        if (streamingService) {
          streamingService.stopStreaming();
        }
        set(initialState);
      }
    }),
    {
      name: 'wav-streaming-store',
    }
  )
);