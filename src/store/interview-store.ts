// é¢è¯•çŠ¶æ€ç®¡ç† - ä½¿ç”¨Zustand

import React from 'react';
import { create } from 'zustand';
import { devtools } from 'zustand/middleware';
import { 
  InterviewSession, 
  TranscriptionSegment, 
  QuestionSuggestion,
  AppError 
} from '@/types';
import { 
  getStorageService, 
  getAudioService, 
  getTranslationService 
} from '@/services';

interface InterviewState {
  // å½“å‰é¢è¯•çŠ¶æ€
  currentSession: InterviewSession | null;
  isRecording: boolean;
  isPaused: boolean;
  recordingDuration: number;
  
  // è½¬å½•å’Œç¿»è¯‘çŠ¶æ€
  segments: TranscriptionSegment[];
  isProcessingAudio: boolean;
  isTranslating: boolean;
  
  // å½“å‰æ´»è·ƒçš„å¯¹è¯æ®µè½ - ç”¨äºå®æ—¶æ›´æ–°æ˜¾ç¤º
  activeSegment: {
    id: string;
    fragments: string[]; // æ”¶é›†çš„æ–‡æœ¬ç¢ç‰‡
    mergedText: string; // åˆå¹¶åçš„å½“å‰æ˜¾ç¤ºæ–‡æœ¬
    translatedText: string; // å½“å‰ç¿»è¯‘æ–‡æœ¬
    confidence: number;
    startTime: number;
    lastUpdateTime: number;
    lastFragmentTime: number; // æœ€åä¸€ä¸ªç¢ç‰‡çš„æ—¶é—´
    isTranslating: boolean;
  } | null;
  
  // ç¢ç‰‡å¤„ç†çŠ¶æ€
  fragmentProcessing: {
    lastProcessedAudioSize: number; // è·Ÿè¸ªéŸ³é¢‘å¤§å°è€Œéå—æ•°
    silenceStartTime: number;
    isInSilence: boolean;
  };
  
  // é—®é¢˜å»ºè®®
  questionSuggestions: QuestionSuggestion[];
  isLoadingSuggestions: boolean;
  
  // å†å²è®°å½•
  sessions: InterviewSession[];
  
  // é”™è¯¯å¤„ç†
  error: AppError | null;
  
  // é…ç½®
  config: {
    openaiApiKey: string;
    autoTranslate: boolean;
    autoSuggestQuestions: boolean;
    language: {
      source: 'en' | 'zh';
      target: 'en' | 'zh';
    };
  };
}

interface InterviewActions {
  // é¢è¯•ä¼šè¯ç®¡ç†
  startInterview: (candidateName: string, position: string) => Promise<void>;
  pauseInterview: () => Promise<void>;
  resumeInterview: () => Promise<void>;
  stopInterview: () => Promise<void>;
  
  // å½•éŸ³æ§åˆ¶
  startRecording: () => Promise<void>;
  stopRecording: () => Promise<void>;
  
  // éŸ³é¢‘å¤„ç†
  processAudioChunk: (audioBlob: Blob) => Promise<void>;
  addSegment: (segment: Omit<TranscriptionSegment, 'id'>) => void;
  
  // ç¢ç‰‡å¤„ç†æ ¸å¿ƒæ–¹æ³•
  processTextFragment: (text: string, confidence: number, audioSize: number) => void;
  updateActiveSegmentDisplay: () => void;
  finalizeActiveSegment: () => void;
  checkSilenceAndFinalize: () => void;
  
  // ç¢ç‰‡åˆå¹¶å’Œæ¸…ç†
  mergeFragments: (fragments: string[]) => string;
  extractNewFragment: (newText: string, existingFragments: string[]) => string;
  calculateTextSimilarity: (text1: string, text2: string) => number;
  findTextDifference: (oldText: string, newText: string) => string;
  
  // å®æ—¶ç¿»è¯‘
  translateActiveSegment: () => Promise<void>;
  
  // è¾…åŠ©å¤„ç†æ–¹æ³•
  transcribeAudio: (audioBlob: Blob) => Promise<any>;
  createSegment: (transcriptionResult: any) => Omit<TranscriptionSegment, 'id'>;
  processSegmentPostActions: (segmentId: string) => Promise<void>;
  handleAudioProcessingError: (error: unknown) => void;
  shouldFinalizeSpeech: (newText: string) => boolean;
  mergeTranscriptionTexts: (oldText: string, newText: string) => string;
  isTextComplete: (text: string) => boolean;
  isTextSubstantiallyEqual: (text1: string, text2: string) => boolean;
  extractNewContent: (text: string, existingSegments: TranscriptionSegment[]) => string;
  
  // ç¿»è¯‘
  translateSegment: (segmentId: string) => Promise<void>;
  
  // é—®é¢˜å»ºè®®
  loadQuestionSuggestions: () => Promise<void>;
  
  // æ•°æ®ç®¡ç†
  loadSessions: () => Promise<void>;
  deleteSession: (sessionId: string) => Promise<void>;
  
  // é…ç½®ç®¡ç†
  updateConfig: (config: Partial<InterviewState['config']>) => void;
  
  // é”™è¯¯å¤„ç†
  setError: (error: AppError | null) => void;
  clearError: () => void;
  
  // é‡ç½®çŠ¶æ€
  reset: () => void;
}

type InterviewStore = InterviewState & InterviewActions;

const initialState: InterviewState = {
  currentSession: null,
  isRecording: false,
  isPaused: false,
  recordingDuration: 0,
  segments: [],
  isProcessingAudio: false,
  isTranslating: false,
  activeSegment: null,
  fragmentProcessing: {
    lastProcessedAudioSize: 0,
    silenceStartTime: 0,
    isInSilence: false
  },
  questionSuggestions: [],
  isLoadingSuggestions: false,
  sessions: [],
  error: null,
  config: {
    openaiApiKey: '',
    autoTranslate: true,
    autoSuggestQuestions: true,
    language: {
      source: 'en',
      target: 'zh'
    }
  }
};

export const useInterviewStore = create<InterviewStore>()(
  devtools(
    (set, get) => ({
      ...initialState,

      // é¢è¯•ä¼šè¯ç®¡ç†
      startInterview: async (candidateName: string, position: string) => {
        try {
          const session: InterviewSession = {
            id: `interview-${Date.now()}`,
            candidateName,
            position,
            startTime: new Date(),
            status: 'recording',
            segments: []
          };

          await getStorageService().saveInterview(session);
          
          set({ 
            currentSession: session,
            segments: [],
            error: null 
          });
        } catch (error) {
          get().setError({
            code: 'START_INTERVIEW_FAILED',
            message: 'å¼€å§‹é¢è¯•å¤±è´¥',
            details: error,
            timestamp: new Date()
          });
        }
      },

      pauseInterview: async () => {
        try {
          const { currentSession } = get();
          if (!currentSession) return;

          const updatedSession = {
            ...currentSession,
            status: 'paused' as const
          };

          await getStorageService().updateInterview(
            currentSession.id, 
            { status: 'paused' }
          );
          
          if (typeof window !== 'undefined') {
            await getAudioService().pauseRecording();
          }
          
          set({ 
            currentSession: updatedSession,
            isPaused: true 
          });
        } catch (error) {
          get().setError({
            code: 'PAUSE_INTERVIEW_FAILED',
            message: 'æš‚åœé¢è¯•å¤±è´¥',
            details: error,
            timestamp: new Date()
          });
        }
      },

      resumeInterview: async () => {
        try {
          const { currentSession } = get();
          if (!currentSession) return;

          const updatedSession = {
            ...currentSession,
            status: 'recording' as const
          };

          await getStorageService().updateInterview(
            currentSession.id, 
            { status: 'recording' }
          );
          
          if (typeof window !== 'undefined') {
            await getAudioService().resumeRecording();
          }
          
          set({ 
            currentSession: updatedSession,
            isPaused: false 
          });
        } catch (error) {
          get().setError({
            code: 'RESUME_INTERVIEW_FAILED',
            message: 'æ¢å¤é¢è¯•å¤±è´¥',
            details: error,
            timestamp: new Date()
          });
        }
      },

      stopInterview: async () => {
        try {
          const { currentSession, segments } = get();
          if (!currentSession) return;

          const updatedSession = {
            ...currentSession,
            status: 'completed' as const,
            endTime: new Date(),
            segments
          };

          await getStorageService().updateInterview(
            currentSession.id, 
            updatedSession
          );
          
          if (get().isRecording && typeof window !== 'undefined') {
            await getAudioService().stopRecording();
          }
          
          set({ 
            currentSession: updatedSession,
            isRecording: false,
            isPaused: false,
            recordingDuration: 0
          });

          // åˆ·æ–°ä¼šè¯åˆ—è¡¨
          await get().loadSessions();
        } catch (error) {
          get().setError({
            code: 'STOP_INTERVIEW_FAILED',
            message: 'ç»“æŸé¢è¯•å¤±è´¥',
            details: error,
            timestamp: new Date()
          });
        }
      },

      // å½•éŸ³æ§åˆ¶
      startRecording: async () => {
        try {
          // ç¡®ä¿åœ¨å®¢æˆ·ç«¯æ‰§è¡Œ
          if (typeof window === 'undefined') {
            throw new Error('Recording not available during SSR');
          }
          
          const audioService = getAudioService();
          
          await audioService.startRecording({
            sampleRate: 44100,
            channels: 1,
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          });

          set({ isRecording: true, error: null });

          // å¯åŠ¨å½•éŸ³æ—¶é•¿æ›´æ–°å®šæ—¶å™¨
          const updateDuration = () => {
            if (get().isRecording) {
              set({ recordingDuration: audioService.getRecordingDuration() });
              setTimeout(updateDuration, 1000);
            }
          };
          updateDuration();

        } catch (error) {
          get().setError({
            code: 'START_RECORDING_FAILED',
            message: 'å¼€å§‹å½•éŸ³å¤±è´¥ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™',
            details: error,
            timestamp: new Date()
          });
        }
      },

      stopRecording: async () => {
        try {
          // ç¡®ä¿åœ¨å®¢æˆ·ç«¯æ‰§è¡Œ
          if (typeof window === 'undefined') {
            return;
          }
          
          await getAudioService().stopRecording();
          set({ 
            isRecording: false, 
            isPaused: false,
            recordingDuration: 0 
          });
        } catch (error) {
          get().setError({
            code: 'STOP_RECORDING_FAILED',
            message: 'åœæ­¢å½•éŸ³å¤±è´¥',
            details: error,
            timestamp: new Date()
          });
        }
      },

      // éŸ³é¢‘å¤„ç† - å®ç°æ­£ç¡®çš„ç¢ç‰‡çº§å¤„ç†
      processAudioChunk: async (audioBlob: Blob, metadata?: any) => {
        const actions = get();
        
        try {
          console.log('ğŸµ å¼€å§‹å¤„ç†éŸ³é¢‘å—:', {
            size: audioBlob.size,
            type: audioBlob.type,
            isIncremental: metadata?.isIncremental
          });
          
          set({ isProcessingAudio: true });
          
          // æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„éŸ³é¢‘æ•°æ®éœ€è¦å¤„ç†
          const { fragmentProcessing } = get();
          if (audioBlob.size <= fragmentProcessing.lastProcessedAudioSize) {
            console.log('â­ï¸ éŸ³é¢‘å¤§å°æœªå¢åŠ ï¼Œè·³è¿‡å¤„ç†');
            set({ isProcessingAudio: false });
            return;
          }
          
          // è½¬å½•éŸ³é¢‘
          const transcriptionResult = await actions.transcribeAudio(audioBlob);
          if (!transcriptionResult.text.trim()) {
            console.log('ğŸ“­ è½¬å½•ç»“æœä¸ºç©ºï¼Œæ£€æŸ¥é™éŸ³çŠ¶æ€');
            actions.checkSilenceAndFinalize();
            set({ isProcessingAudio: false });
            return;
          }

          console.log('ğŸ“ è½¬å½•ç»“æœ:', transcriptionResult.text);
          
          // å¤„ç†æ–‡æœ¬ç¢ç‰‡
          actions.processTextFragment(
            transcriptionResult.text, 
            transcriptionResult.confidence,
            audioBlob.size
          );
          
          console.log('âœ… éŸ³é¢‘å¤„ç†å®Œæˆ');
          set({ isProcessingAudio: false });
        } catch (error) {
          actions.handleAudioProcessingError(error);
        }
      },

      // è¾…åŠ©æ–¹æ³•
      transcribeAudio: async (audioBlob: Blob) => {
        // ç¡®ä¿åœ¨å®¢æˆ·ç«¯æ‰§è¡Œ
        if (typeof window === 'undefined') {
          throw new Error('Transcription not available during SSR');
        }
        
        const audioService = getAudioService();
        console.log('å¼€å§‹è°ƒç”¨éŸ³é¢‘è½¬å½•...');
        const result = await audioService.transcribe(audioBlob);
        console.log('è½¬å½•å®Œæˆï¼Œç»“æœ:', result);
        return result;
      },

      createSegment: (transcriptionResult: any) => {
        return {
          id: `segment-${Date.now()}`,
          timestamp: Date.now(),
          originalText: transcriptionResult.text,
          translatedText: '',
          speaker: 'candidate' as const,
          confidence: transcriptionResult.confidence,
          isProcessing: true
        };
      },

      processSegmentPostActions: async (segmentId: string) => {
        const { config } = get();
        
        // è‡ªåŠ¨ç¿»è¯‘
        if (config.autoTranslate) {
          console.log('å¼€å§‹è‡ªåŠ¨ç¿»è¯‘...');
          await get().translateSegment(segmentId);
        } else {
          // æ ‡è®°å¤„ç†å®Œæˆ
          set(state => ({
            segments: state.segments.map(s => 
              s.id === segmentId ? { ...s, isProcessing: false } : s
            )
          }));
        }

        // è‡ªåŠ¨ç”Ÿæˆé—®é¢˜å»ºè®®
        if (config.autoSuggestQuestions) {
          console.log('åŠ è½½é—®é¢˜å»ºè®®...');
          await get().loadQuestionSuggestions();
        }
      },

      handleAudioProcessingError: (error: unknown) => {
        console.error('éŸ³é¢‘å¤„ç†å¤±è´¥:', error);
        set({ isProcessingAudio: false });
        
        const errorMessage = error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯';
        
        get().setError({
          code: 'PROCESS_AUDIO_FAILED',
          message: `éŸ³é¢‘å¤„ç†å¤±è´¥: ${errorMessage}`,
          details: error,
          timestamp: new Date()
        });
      },

      addSegment: (segmentData) => {
        const segment: TranscriptionSegment = {
          ...segmentData,
          id: `segment-${Date.now()}`
        };

        set(state => ({
          segments: [...state.segments, segment]
        }));

        // ä¿å­˜åˆ°å½“å‰ä¼šè¯
        const { currentSession } = get();
        if (currentSession) {
          const updatedSession = {
            ...currentSession,
            segments: [...get().segments]
          };
          getStorageService().updateInterview(currentSession.id, { segments: updatedSession.segments });
        }
      },

      // ç¿»è¯‘
      translateSegment: async (segmentId: string) => {
        try {
          // ç¡®ä¿åœ¨å®¢æˆ·ç«¯æ‰§è¡Œ
          if (typeof window === 'undefined') {
            throw new Error('Translation not available during SSR');
          }
          
          set({ isTranslating: true });
          
          const { segments, config } = get();
          const segment = segments.find(s => s.id === segmentId);
          
          if (!segment) return;

          const translationService = getTranslationService();
          const translationResult = await translationService.translate(
            segment.originalText,
            config.language.source,
            config.language.target
          );

          set(state => ({
            segments: state.segments.map(s =>
              s.id === segmentId
                ? { ...s, translatedText: translationResult.translatedText }
                : s
            ),
            isTranslating: false
          }));
        } catch (error) {
          set({ isTranslating: false });
          get().setError({
            code: 'TRANSLATION_FAILED',
            message: 'ç¿»è¯‘å¤±è´¥',
            details: error,
            timestamp: new Date()
          });
        }
      },

      // é—®é¢˜å»ºè®®
      loadQuestionSuggestions: async () => {
        try {
          // ç¡®ä¿åœ¨å®¢æˆ·ç«¯æ‰§è¡Œ
          if (typeof window === 'undefined') {
            throw new Error('Question suggestions not available during SSR');
          }
          
          set({ isLoadingSuggestions: true });
          
          const { segments } = get();
          const recentTexts = segments
            .slice(-5)
            .map(s => s.originalText);

          if (recentTexts.length === 0) {
            set({ 
              questionSuggestions: [],
              isLoadingSuggestions: false 
            });
            return;
          }

          const translationService = getTranslationService();
          const suggestions = await translationService.suggestQuestions(recentTexts);

          set({ 
            questionSuggestions: suggestions,
            isLoadingSuggestions: false 
          });
        } catch (error) {
          set({ isLoadingSuggestions: false });
          get().setError({
            code: 'LOAD_SUGGESTIONS_FAILED',
            message: 'åŠ è½½é—®é¢˜å»ºè®®å¤±è´¥',
            details: error,
            timestamp: new Date()
          });
        }
      },

      // æ•°æ®ç®¡ç†
      loadSessions: async () => {
        try {
          const storageService = getStorageService();
          const sessions = await storageService.listInterviews(20, 0);
          set({ sessions });
        } catch (error) {
          get().setError({
            code: 'LOAD_SESSIONS_FAILED',
            message: 'åŠ è½½å†å²è®°å½•å¤±è´¥',
            details: error,
            timestamp: new Date()
          });
        }
      },

      deleteSession: async (sessionId: string) => {
        try {
          await getStorageService().deleteInterview(sessionId);
          await get().loadSessions();
        } catch (error) {
          get().setError({
            code: 'DELETE_SESSION_FAILED',
            message: 'åˆ é™¤é¢è¯•è®°å½•å¤±è´¥',
            details: error,
            timestamp: new Date()
          });
        }
      },

      // é…ç½®ç®¡ç†
      updateConfig: (configUpdate) => {
        set(state => ({
          config: { ...state.config, ...configUpdate }
        }));
        
        // ä¿å­˜åˆ°localStorageï¼ˆå»¶è¿Ÿåˆ°å®¢æˆ·ç«¯ï¼‰
        setTimeout(() => {
          if (typeof window !== 'undefined' && typeof localStorage !== 'undefined') {
            try {
              const newConfig = { ...get().config, ...configUpdate };
              localStorage.setItem('interview-assistant-config', JSON.stringify(newConfig));
            } catch (error) {
              console.warn('Failed to save config to localStorage:', error);
            }
          }
        }, 0);
      },

      // ç¢ç‰‡å¤„ç†æ ¸å¿ƒæ–¹æ³• - ç®€åŒ–ç‰ˆæœ¬
      processTextFragment: (text: string, confidence: number, audioSize: number) => {
        const { activeSegment, fragmentProcessing } = get();
        const now = Date.now();
        const trimmedText = text.trim();
        
        console.log('ğŸ¯ processTextFragment è¾“å…¥:', {
          inputText: trimmedText,
          confidence,
          currentMergedText: activeSegment?.mergedText || '(ç©º)'
        });
        
        // ä½¿ç”¨ç®€åŒ–çš„ç´¯ç§¯æ–‡æœ¬å¤„ç†é€»è¾‘
        const currentMergedText = activeSegment?.mergedText || '';
        
        // å®Œå…¨ç›¸åŒï¼Œæ— æ–°å†…å®¹
        if (trimmedText === currentMergedText) {
          console.log('âš ï¸ æ–‡æœ¬å®Œå…¨é‡å¤ï¼Œè·³è¿‡');
          return;
        }
        
        // æ–°æ–‡æœ¬æ›´çŸ­ï¼Œå¯èƒ½æ˜¯é”™è¯¯ï¼Œè·³è¿‡
        if (trimmedText.length < currentMergedText.length) {
          console.log('âš ï¸ æ–°æ–‡æœ¬æ›´çŸ­ï¼Œå¯èƒ½æ˜¯é”™è¯¯');
          return;
        }
        
        let newMergedText = trimmedText;
        let isNewSegment = false;
        
        if (!activeSegment) {
          // ç¬¬ä¸€ä¸ªæ®µè½
          isNewSegment = true;
          console.log('ğŸ†• åˆ›å»ºé¦–ä¸ªæ´»è·ƒæ®µè½:', trimmedText);
        } else if (trimmedText.startsWith(currentMergedText)) {
          // ç´¯ç§¯æ–‡æœ¬ï¼Œæå–æ–°å¢éƒ¨åˆ†
          const newPart = trimmedText.slice(currentMergedText.length);
          console.log('âœ… æ£€æµ‹åˆ°æ–°å¢å†…å®¹:', {
            currentText: currentMergedText.slice(-30) + '...',
            newPart: newPart || '(æ— æ–°å¢)',
            fullText: trimmedText
          });
          newMergedText = trimmedText;
        } else {
          // å®Œå…¨ä¸åŒçš„æ–°æ–‡æœ¬ï¼Œå¯èƒ½æ˜¯æ–°å¥å­å¼€å§‹
          console.log('ğŸš€ æ£€æµ‹åˆ°å…¨æ–°æ–‡æœ¬ï¼Œå¼€å§‹æ–°æ®µè½');
          // å…ˆå®Œæˆå½“å‰æ®µè½
          if (activeSegment) {
            get().finalizeActiveSegment();
          }
          isNewSegment = true;
        }
        
        if (isNewSegment) {
          // åˆ›å»ºæ–°çš„æ´»è·ƒæ®µè½
          const segmentId = `segment-${now}`;
          set({
            activeSegment: {
              id: segmentId,
              fragments: [newMergedText],
              mergedText: newMergedText,
              translatedText: '',
              confidence,
              startTime: now,
              lastUpdateTime: now,
              lastFragmentTime: now,
              isTranslating: false
            },
            fragmentProcessing: {
              ...fragmentProcessing,
              lastProcessedAudioSize: audioSize,
              silenceStartTime: now,
              isInSilence: false
            }
          });
        } else {
          // æ›´æ–°ç°æœ‰æ´»è·ƒæ®µè½
          set({
            activeSegment: {
              id: activeSegment!.id,
              fragments: [...activeSegment!.fragments, newMergedText],
              mergedText: newMergedText,
              translatedText: activeSegment!.translatedText,
              confidence: Math.max(activeSegment!.confidence, confidence),
              startTime: activeSegment!.startTime,
              lastUpdateTime: now,
              lastFragmentTime: now,
              isTranslating: activeSegment!.isTranslating
            },
            fragmentProcessing: {
              ...fragmentProcessing,
              lastProcessedAudioSize: audioSize,
              silenceStartTime: now,
              isInSilence: false
            }
          });
        }
        
        console.log('ğŸ”„ æ®µè½æ›´æ–°å®Œæˆ:', newMergedText);
        
        // ç«‹å³æ›´æ–°æ˜¾ç¤ºå’Œç¿»è¯‘
        get().updateActiveSegmentDisplay();
        
        // æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†æ®µ
        get().checkSilenceAndFinalize();
      },

      updateActiveSegmentDisplay: () => {
        const { activeSegment, config } = get();
        if (!activeSegment) return;
        
        console.log('ğŸ–¼ï¸ æ›´æ–°æ˜¾ç¤º:', activeSegment.mergedText);
        
        // å¦‚æœå¯ç”¨è‡ªåŠ¨ç¿»è¯‘ä¸”å½“å‰æ²¡åœ¨ç¿»è¯‘
        if (config.autoTranslate && !activeSegment.isTranslating) {
          get().translateActiveSegment();
        }
      },

      checkSilenceAndFinalize: () => {
        const { activeSegment, fragmentProcessing } = get();
        if (!activeSegment) return;
        
        const now = Date.now();
        const silenceDuration = now - activeSegment.lastFragmentTime;
        const textLength = activeSegment.mergedText.length;
        
        // åˆ¤æ–­åˆ†æ®µæ¡ä»¶
        const hasLongSilence = silenceDuration > 2000; // 2ç§’é™éŸ³
        const hasEndPunctuation = /[.!?ã€‚ï¼ï¼Ÿ]$/.test(activeSegment.mergedText.trim());
        const hasLongText = textLength > 100; // é•¿æ–‡æœ¬è‡ªåŠ¨åˆ†æ®µ
        const seemsComplete = get().isTextComplete(activeSegment.mergedText);
        
        if ((hasLongSilence && seemsComplete) || hasEndPunctuation || hasLongText) {
          console.log('ğŸ æ£€æµ‹åˆ°åˆ†æ®µæ¡ä»¶ï¼Œå®Œæˆå½“å‰æ®µè½');
          get().finalizeActiveSegment();
        }
      },

      finalizeActiveSegment: () => {
        const { activeSegment } = get();
        if (!activeSegment || activeSegment.mergedText.trim().length === 0) {
          set({ activeSegment: null });
          return;
        }
        
        console.log('âœ… å®Œæˆæ®µè½:', activeSegment.mergedText);
        
        // åˆ›å»ºæœ€ç»ˆçš„è½¬å½•æ®µ
        const segment: TranscriptionSegment = {
          id: activeSegment.id,
          timestamp: activeSegment.startTime,
          originalText: activeSegment.mergedText,
          translatedText: activeSegment.translatedText,
          speaker: 'candidate',
          confidence: activeSegment.confidence,
          isProcessing: false
        };
        
        // æ·»åŠ åˆ°segmentsåˆ—è¡¨
        set(state => ({
          segments: [...state.segments, segment],
          activeSegment: null // æ¸…ç©ºæ´»è·ƒæ®µè½ï¼Œå‡†å¤‡ä¸‹ä¸€ä¸ª
        }));
        
        // å¦‚æœè¿˜æ²¡æœ‰ç¿»è¯‘ï¼Œå¼‚æ­¥å®Œæˆç¿»è¯‘
        if (!segment.translatedText) {
          get().translateSegment(segment.id);
        }
        
        // ç”Ÿæˆé—®é¢˜å»ºè®®
        if (get().config.autoSuggestQuestions) {
          get().loadQuestionSuggestions();
        }
      },

      // å®æ—¶ç¿»è¯‘æ´»è·ƒæ®µè½
      translateActiveSegment: async () => {
        const { activeSegment } = get();
        if (!activeSegment || activeSegment.isTranslating || activeSegment.mergedText.trim().length < 3) {
          return;
        }
        
        // æ ‡è®°ä¸ºç¿»è¯‘ä¸­
        set(state => state.activeSegment ? {
          activeSegment: { ...state.activeSegment, isTranslating: true }
        } : {});
        
        try {
          console.log('ğŸŒ å¼€å§‹ç¿»è¯‘æ´»è·ƒæ®µè½:', activeSegment.mergedText);
          
          const translationService = getTranslationService();
          const result = await translationService.translate(
            activeSegment.mergedText,
            'en',
            'zh'
          );
          
          // æ›´æ–°ç¿»è¯‘ç»“æœ
          set(state => state.activeSegment ? {
            activeSegment: {
              ...state.activeSegment,
              translatedText: result.translatedText,
              isTranslating: false
            }
          } : {});
          
          console.log('âœ… ç¿»è¯‘å®Œæˆ:', result.translatedText);
        } catch (error) {
          console.error('âŒ ç¿»è¯‘å¤±è´¥:', error);
          set(state => state.activeSegment ? {
            activeSegment: { ...state.activeSegment, isTranslating: false }
          } : {});
        }
      },

      // é”™è¯¯å¤„ç†
      setError: (error) => set({ error }),
      clearError: () => set({ error: null }),

      // ä¿ç•™è¿™ä¸ªæ–¹æ³•ä½†ä¸å®ç°ï¼Œç”¨äºå…¼å®¹æ€§
      updateCurrentSpeech: (text: string, confidence: number, metadata?: any) => {
        console.log('updateCurrentSpeech called but not implemented in new architecture');
      },

      // ç®€åŒ–çš„å…¼å®¹æ€§æ–¹æ³•
      finalizeCurrentSpeech: () => {
        console.log('finalizeCurrentSpeech called but not implemented in new architecture');
      },

      // ç®€åŒ–çš„å…¼å®¹æ€§æ–¹æ³•
      resetCurrentSpeech: () => {
        console.log('resetCurrentSpeech called but not implemented in new architecture');
      },

      detectSilenceAndFinalize: () => {
        console.log('detectSilenceAndFinalize called but not implemented in new architecture');
      },

      performDelayedMerge: () => {
        console.log('performDelayedMerge called but not implemented in new architecture');
      },

      findMergeCandidates: (segments: TranscriptionSegment[]) => {
        return [];
      },

      areSegmentsRelated: (text1: string, text2: string) => {
        return false;
      },

      mergeSegments: (segments: TranscriptionSegment[]) => {
        console.log('mergeSegments called but not implemented in new architecture');
      },

      // ç®€åŒ–çš„å…¼å®¹æ€§æ–¹æ³•
      shouldFinalizeSpeech: (newText: string) => {
        return false;
      },

      isTextComplete: (text: string) => {
        const words = text.trim().split(/\s+/);
        return words.length >= 3;
      },

      isTextSubstantiallyEqual: (text1: string, text2: string) => {
        return text1.trim().toLowerCase() === text2.trim().toLowerCase();
      },

      extractNewContent: (text: string, existingSegments: TranscriptionSegment[]) => {
        return text.trim();
      },

      // ç®€åŒ–çš„å…¼å®¹æ€§æ–¹æ³•
      mergeFragments: (fragments: string[]) => {
        return fragments.join(' ').trim();
      },

      extractNewFragment: (newText: string, existingFragments: string[]) => {
        return newText.trim();
      },

      calculateTextSimilarity: (text1: string, text2: string) => {
        return text1 === text2 ? 1 : 0;
      },

      findTextDifference: (oldText: string, newText: string) => {
        return newText;
      },

      mergeTranscriptionTexts: (oldText: string, newText: string) => {
        return newText.length > oldText.length ? newText : oldText;
      },

      // é‡ç½®çŠ¶æ€
      reset: () => set(initialState)
    }),
    {
      name: 'interview-store',
    }
  )
);

// å®¢æˆ·ç«¯é…ç½®åˆå§‹åŒ–Hook
export const useInitializeConfig = () => {
  const updateConfig = useInterviewStore(state => state.updateConfig);
  
  React.useEffect(() => {
    if (typeof window !== 'undefined' && typeof localStorage !== 'undefined') {
      try {
        const savedConfig = localStorage.getItem('interview-assistant-config');
        if (savedConfig) {
          const config = JSON.parse(savedConfig);
          updateConfig(config);
        }
      } catch (error) {
        console.warn('Failed to load saved config:', error);
      }
    }
  }, [updateConfig]);
};